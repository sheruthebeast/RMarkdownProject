knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
#Package management (you don't need to do anything with this, it just makes sure you have all the #packages you need for this assignment):
# check if pacman is install, if not, install it from cran and load
if (!require("pacman")) {
install.packages("pacman", dependencies=TRUE, repos='http://cran.rstudio.com/')
library(pacman)
}
# packages used in this report:
pacman::p_load("tidyverse", "unvotes", "countrycode", "lubridate", "forcats", "nycflights13")
#You'll need this function later
make_datetime_100 <- function(year, month, day, time) {
make_datetime(year, month, day, time %/% 100, time %% 100)
}
#Answer (6-c)
library(lubridate)
flights_dt %>%
mutate(hours = hour(sched_dep_time)) %>%
group_by(hours) %>%
summarise(delay_time = mean(dep_delay)) %>%
ggplot(aes(y = delay_time, x = hours)) +
geom_point() +
geom_smooth()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
#The code used used to collect your tweets should go here
library(rtweet)
install.packages("rtweet")
#The code used used to collect your tweets should go here
library(rtweet)
library(data.table)
#Using search_tweets to pull historical tweets with #BlackFriday
bf_hist_rest <- search_tweets(
"#BlackFriday",
n = 1000,
include_rts = FALSE
)
#Adding a new variable "Collection_Method" - indicating the method the tweet was collected with
method1 = c("Rest API")
bf_hist_rest$Collection_method <- method1
#Using stream_tweets to pull real-time tweets with #BlackFriday for 2 hours
stream_tweets(
"#BlackFriday",
timeout = 60 * 60 * 2,
file_name = "tweetsaboutBlackFriday.json",
parse = FALSE
)
#The code used used to collect your tweets should go here
library(rtweet)
library(data.table)
#Using search_tweets to pull historical tweets with #BlackFriday
bf_hist_rest <- search_tweets(
"#BlackFriday",
n = 1000,
include_rts = FALSE
)
#Adding a new variable "Collection_Method" - indicating the method the tweet was collected with
method1 = c("Rest API")
bf_hist_rest$Collection_method <- method1
#Using stream_tweets to pull real-time tweets with #BlackFriday for 2 hours
stream_tweets(
"#BlackFriday",
timeout = 60 ,
file_name = "tweetsaboutBlackFriday.json",
parse = FALSE
)
#Parsing the stream into a data-frame
bf_real_stream <- parse_stream("tweetsaboutBlackFriday.json")
#Adding a new variable "Collection_Method" - indicating the method the tweet was collected with
method2 = c("Streaming API")
bf_real_stream$Collection_method <- method2
#Combining the two data-frames into one
bf_combine_tweets <- rbind(bf_hist_rest, bf_real_stream)
#The code used used to collect your tweets should go here
library(rtweet)
library(data.table)
#Using search_tweets to pull historical tweets with #BlackFriday
bf_hist_rest <- search_tweets(
"#BlackFriday",
n = 1000,
include_rts = FALSE
)
#Adding a new variable "Collection_Method" - indicating the method the tweet was collected with
method1 = c("Rest API")
bf_hist_rest$Collection_method <- method1
#Using stream_tweets to pull real-time tweets with #BlackFriday for 2 hours
stream_tweets(
"#BlackFriday",
timeout = 60*60*2 ,
file_name = "tweetsaboutBlackFriday.json",
parse = FALSE
)
rm(bf_hist_rest)
rm(bf_real_stream)
rm(method1)
rm(method2)
rm(make_datetime_100())
install.packages("tigerstats")
library(tigerstats)
library(knitr)
knitr::opts_chunk$set(echo = FALSE)
head(sat)
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("knitr")
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
library(tigerstats)
library(knitr)
knitr::opts_chunk$set(echo = FALSE)
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
library(tigerstats)
library(knitr)
opts_chunk$set(echo = FALSE)
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
knit_child("Sample.Rmd")
---
title: "Analysis"
output: word_document
---
getwd()
getwd()
library(tigerstats)
library(knitr)
options(knitr.duplicate.label = "allow")
opts_chunk$set(echo = FALSE)
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
library(tigerstats)
library(knitr)
opts_chunk$set(echo = FALSE)
options(knitr.duplicate.label = "allow")
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
knitr::opts_chunk$set(echo = TRUE)
library(tigerstats)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
library(tigerstats)
library(knitr)
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
xyplot(sat~salary,
data=sat,
type=c("p","smooth"),
pch=19,
main="Salaryand SAT Scores",
xlab="mean teacher salary (1000$)",
ylab="mean SAT score"
)
install.packages("officedown")
install.packages("kableExtra")
install.packages(officer)
install.packages("officer")
install.packages("flextable")
install.packages("qflextable")
?qflextable
library(tigerstats)
data(sat)
force(sat)
View(sat)
